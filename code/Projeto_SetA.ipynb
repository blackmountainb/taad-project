{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ea8194",
   "metadata": {},
   "source": [
    "# Appling machine learning to audio analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32828f32",
   "metadata": {},
   "source": [
    "First we want to upload our labeled and unlabeled dataset for future use to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32435a3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Dependencies were already installed previously on ubuntu\n",
    "### Comet: experiment tracking and visual tools\n",
    "\n",
    "from comet_ml import Experiment\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa # audio analysis\n",
    "import librosa.display # this submodule needs to be imported explicitly\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile as wav\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f86e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc810254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential: creates a sequential model, ideal to create plain stack of layers\n",
    "# each layer has exactly one input tensor and one output tensor\n",
    "\n",
    "# Layers: basic building blacks of neural networks in Keras, consists of a\n",
    "# tensor-in and tensor-out computation function and some state\n",
    "\n",
    "# Dense, Dropout and Activartion are classes from layers:\n",
    "# Activation and dense: Core layers. Activation applies an activation function\n",
    "# to an output. The output has the same shape as the input.\n",
    "# Dropout: regularization layer.\n",
    "\n",
    "# Adam: it's an algorithm, an optimization, stochastic gradient descent method\n",
    "#based on adaptive estimation of first and second order moments.\n",
    "\n",
    "# to_categorical: converts a class vectors (integers) to a binary class matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b22f8aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "# Keras now is fully integrated to Tensorflow, so to_categorical and Adam\n",
    "# can't be imported directly from keras, therefore, the update:\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c752792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To play audio file:\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49aa3b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/negromontebs/seta/4595fd200a904a17979327e1e0952ec5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Comet Experiment, to capture any and all artifacts\n",
    "# such as audio files, visualization, model, dataset, system information and training metrics\n",
    "experiment = Experiment(api_key = \"Xa6eGiuYFngDcAJ9PVY1WpZp0\", project_name = \"SetA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d6a45f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artifact', 'extrahls', 'murmur', 'normal', 'unlab']\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../csvFiles/set_a.csv')\n",
    "\n",
    "\n",
    "# Create a list of the labels. Currently there are 5 labels: 'artifact', 'extrahls', 'murmur', 'normal', 'unlab'\n",
    "labels = list(df['label'].unique())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a4dc0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_a/artifact__201012172012.wav\n",
      "set_a/extrahls__201101070953.wav\n",
      "set_a/murmur__201101051104.wav\n",
      "set_a/normal__201101070538.wav\n",
      "set_a/Aunlabelledtest__201012172010.wav\n"
     ]
    }
   ],
   "source": [
    "# grabs a single audio file from each class\n",
    "files = dict()\n",
    "datasetSize = 1\n",
    "\n",
    "#Iteration over the labels and \n",
    "\n",
    "for i in range(len(labels)):\n",
    "    \n",
    "    #if the dataset contains itens with  the iterated label\n",
    "    labelBoolean = (df['label'] == labels[i])\n",
    "    #pick those items and make a new dataFrame with a spefic size\n",
    "    dfItem = df[labelBoolean][:datasetSize]\n",
    "    #reset the index to for easier selection\n",
    "    tmp = dfItem.reset_index()\n",
    "    #string with the directory\n",
    "    path = '{}'.format(tmp['fname'][0])\n",
    "    #save the string to the dictionary\n",
    "    print(path)\n",
    "    files[labels[i]] = '../' + path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07ae3956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../set_a/artifact__201012172012.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/picopreto/.virtualenvs/taad/lib/python3.6/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/taad/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/taad/lib/python3.6/site-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/taad/lib/python3.6/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         _error_check(_snd.sf_error(file_ptr),\n\u001b[0;32m-> 1184\u001b[0;31m                      \"Error opening {0!r}: \".format(self.name))\n\u001b[0m\u001b[1;32m   1185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/taad/lib/python3.6/site-packages/soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[0;34m(err, prefix)\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error opening '../set_a/artifact__201012172012.wav': File contains data in an unknown format.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3a78174d13b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaveplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/taad/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPurePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/taad/lib/python3.6/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/taad/lib/python3.6/site-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/taad/lib/python3.6/site-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maifc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0maifc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Return to the beginning of the file to try the next reader.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/aifc.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mAifc_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mAifc_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/aifc.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;31m# assume it is an open file object already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitfp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/aifc.py\u001b[0m in \u001b[0;36minitfp\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_soundpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb'FORM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'file does not start with FORM id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/chunk.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, align, bigendian, inclheader)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunkname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunkname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrflag\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To plot the waveforms, using librosa's display.waveplot function:\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "#experiment.log_image('label_examples.png')\n",
    "fig.subplots_adjust(hspace = 0.4, wspace = 0.4)\n",
    "\n",
    "\n",
    "for i, lab in enumerate(labels):\n",
    "    # i = index\n",
    "    # lab = name of the label at current index\n",
    "    fn = files[lab]\n",
    "    print(fn)\n",
    "    fig.add_subplot(5,2,1+i)\n",
    "    plt.title(lab)\n",
    "    data, sample_rate = librosa.load(fn)\n",
    "    librosa.display.waveplot(data, sr = sample_rate)\n",
    "    \n",
    "plt.savefig('../images/label_examples.png')\n",
    "\n",
    "# Log graphic of waveforms to comet:\n",
    "experiment.log_image('../images/label_examples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c992fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log audio files to Comet for debugging\n",
    "for label in labels:\n",
    "    fn = files[label]\n",
    "    experiment.log_audio(fn, metadata = {'name': label})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf343ccc",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2db6e3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pick an audio file\n",
    "fn = files[\"artifact\"]\n",
    "#get its sample rate and librosa sample rate and bit depth\n",
    "librosa_audio, librosa_sample_rate = librosa.load(fn)\n",
    "scipy_sample_rate, scipy_audio = wav.read(fn)\n",
    "\n",
    "print(\"Original sample rate: {}\".format(scipy_sample_rate))\n",
    "print(\"Librosa sample rate: {}\".format(librosa_sample_rate))\n",
    "\n",
    "print('Original audio file min~max range: {} to {}'.format(np.min(scipy_audio), np.max(scipy_audio)))\n",
    "print('Librosa audio file min~max range: {0:.2f} to {0:.2f}'.format(np.min(librosa_audio), np.max(librosa_audio)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf553b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the original audio\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(scipy_audio)\n",
    "plt.savefig('../images/original_audio.png')\n",
    "experiment.log_image('../images/original_audio.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f910ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the librosa audio mono sound\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(librosa_audio)\n",
    "plt.savefig('../images/librosa_audio.png')\n",
    "experiment.log_image('../images/librosa_audio.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565a4b28",
   "metadata": {},
   "source": [
    "<h2> Separating S1 and S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad694daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "timing = pd.read_csv('set_a_timing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6856ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = dict()\n",
    "S2 = dict()\n",
    "\n",
    "file_name = list(timing['fname'].unique())\n",
    "\n",
    "for i in file_name:\n",
    "    S1[i] = []\n",
    "    S2[i] = []\n",
    "\n",
    "for i in range(len(timing)):\n",
    "    if timing.sound[i] == 'S1':\n",
    "        S1[timing.fname[i]].append(timing.loc[i,'location'])\n",
    "    else:\n",
    "        S2[timing.fname[i]].append(timing.loc[i,'location'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5a0174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to track time and beats from every audio\n",
    "def extract_beat(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name) \n",
    "    # tracks the beats using time series input\n",
    "    tempo, beats = librosa.beat.beat_track(audio, sr=sample_rate)\n",
    "    return tempo, beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c67bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots the mel spectogram of one audio\n",
    "hop_length = 512\n",
    "tempo, beats = librosa.beat.beat_track(librosa_audio, sr=librosa_sample_rate)\n",
    "onset_env = librosa.onset.onset_strength(librosa_audio, sr=librosa_sample_rate, aggregate=np.median)\n",
    "fig, ax = plt.subplots(nrows=2, sharex=True)\n",
    "times = librosa.times_like(onset_env, sr=librosa_sample_rate, hop_length=hop_length)\n",
    "M = librosa.feature.melspectrogram(librosa_audio, sr=librosa_sample_rate, hop_length=hop_length)\n",
    "librosa.display.specshow(librosa.power_to_db(M, ref=np.max),\n",
    "                         y_axis='mel', x_axis='time', hop_length=hop_length,\n",
    "                         ax=ax[0])\n",
    "ax[0].label_outer()\n",
    "ax[0].set(title='Mel spectrogram')\n",
    "ax[1].plot(times, librosa.util.normalize(onset_env), label='Onset strength')\n",
    "ax[1].vlines(times[beats], 0, 1, alpha=0.5, color='r', linestyle='--', label='Beats')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd7bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for the beats, time, label\n",
    "beats = [] \n",
    "time = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a944ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each sound file and extract the beats \n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    absolutePath = os.path.abspath(\"\")\n",
    "    fname = str(row[\"fname\"])\n",
    "    file_name = os.path.join(absolutePath,fname)\n",
    "    \n",
    "    class_label = row[\"label\"]\n",
    "    \n",
    "    if(class_label != \"unlab\"):\n",
    "        data = extract_beat(file_name)\n",
    "        time.append(data[0])\n",
    "        beats.append(data[1])\n",
    "        labels.append(class_label)\n",
    "    \n",
    "# Convert into a Panda dataframe\n",
    "tb_df = pd.DataFrame(list(zip(beats, time, labels)), columns=['beats','time','class_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e267aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c178f3",
   "metadata": {},
   "source": [
    "## MFCCs - Mel-Frequency Cepstrum Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1548a1",
   "metadata": {},
   "source": [
    "### Extract coefficients from only one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d57e278",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(y=librosa_audio, sr=librosa_sample_rate, n_mfcc = 40)\n",
    "print(mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b48bc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "librosa.display.specshow(mfccs, sr=librosa_sample_rate, x_axis='time')\n",
    "plt.savefig('../images/MFCCs.png')\n",
    "experiment.log_image('../images/MFCCs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643a60c3",
   "metadata": {},
   "source": [
    "### Function to extract the MFCCs from every file in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "     \n",
    "    return mfccs_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6868d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []# Iterate through each sound file and extract the features \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    absolutePath = os.path.abspath(\"../\")\n",
    "    fname = str(row[\"fname\"])\n",
    "    file_name = os.path.join(absolutePath,fname)\n",
    "    \n",
    "    class_label = row[\"label\"]\n",
    "    \n",
    "    if(class_label != \"unlab\"):\n",
    "        data = extract_features(file_name)\n",
    "        features.append([data, class_label])\n",
    "    \n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a1219",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c610201f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "featuresdf.iloc[0]['feature']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69052eeb",
   "metadata": {},
   "source": [
    "## Model building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c381f86",
   "metadata": {},
   "source": [
    "### Trainning and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6a5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 127)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874155a",
   "metadata": {},
   "source": [
    "### Neural Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d400943",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_labels = yy.shape[1]\n",
    "\n",
    "filter_size = 2\n",
    "\n",
    "def build_model_graph(input_shape=(40,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_labels))\n",
    "    model.add(Activation('softmax'))\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') \n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model_graph()\n",
    "\n",
    "# Display model architecture summary \n",
    "model(x_train)\n",
    "model.summary()# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e750c",
   "metadata": {},
   "source": [
    "### Model Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee43c4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: {0:.2%}\".format(score[1]))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: {0:.2%}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d565231b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321af7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
