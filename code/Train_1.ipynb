{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ea8194",
   "metadata": {},
   "source": [
    "# Appling machine learning to audio analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a361c",
   "metadata": {},
   "source": [
    "### Trainning Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32435a3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Dependencies were already installed previously on ubuntu\n",
    "### Comet: experiment tracking and visual tools\n",
    "\n",
    "from comet_ml import Experiment\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa # audio analysis\n",
    "import librosa.display # this submodule needs to be imported explicitly\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile as wav\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f86e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b22f8aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "# Keras now is fully integrated to Tensorflow, so to_categorical and Adam\n",
    "# can't be imported directly from keras, therefore, the update:\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c752792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To play audio file:\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa3b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET WARNING: Failed to check backend version at URL: 'https://www.comet.ml/clientlib/isAlive/ver'\n"
     ]
    }
   ],
   "source": [
    "# Create a Comet Experiment, to capture any and all artifacts\n",
    "# such as audio files, visualization, model, dataset, system information and training metrics\n",
    "experiment = Experiment(api_key = \"Xa6eGiuYFngDcAJ9PVY1WpZp0\", project_name = \"SetA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c178f3",
   "metadata": {},
   "source": [
    "## MFCCs - Mel-Frequency Cepstrum Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643a60c3",
   "metadata": {},
   "source": [
    "### Function to extract the MFCCs from every file in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name) \n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "     \n",
    "    return mfccs_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ac765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../csvFiles/newTiming.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650dc1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6868d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds = []# Iterate through each sound file and extract the sound type\n",
    "cont = 0\n",
    "i =0\n",
    "for index, row in df.iterrows():\n",
    "    file_name = df.loc[index]['fname']\n",
    "    label = df.loc[index]['sound']\n",
    "    if label == 'noiseS2' or label == 'noiseS1':\n",
    "        class_label = label[:5]\n",
    "    else:\n",
    "        class_label = label\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "    if (exists(file_name)):\n",
    "        file_size = os.path.getsize(file_name)\n",
    "        if (file_size>44):\n",
    "            data = extract_features(file_name)\n",
    "            sounds.append([data, class_label])\n",
    "            cont += 1\n",
    "        else:\n",
    "            print(file_name)\n",
    "            \n",
    "print(i, cont)\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(sounds, columns=['soundtype','class_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a1219",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c610201f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "featuresdf.iloc[0]['soundtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a98f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "#experiment.log_image('label_examples.png')\n",
    "fig.subplots_adjust(hspace = 0.4, wspace = 0.4)\n",
    "\n",
    "fig.add_subplot(6,2,1)\n",
    "name = df.loc[411]['fname']\n",
    "print(name)\n",
    "data, sample_rate = librosa.load(name)\n",
    "librosa.display.waveplot(data, sr = sample_rate)\n",
    "dad = extract_features(name)\n",
    "sounds.append([dad,df.loc[411]['sound']])\n",
    "    \n",
    "featuresdf = pd.DataFrame(sounds, columns=['soundtype','class_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69052eeb",
   "metadata": {},
   "source": [
    "## Model building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.soundtype.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c381f86",
   "metadata": {},
   "source": [
    "### Trainning and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6a5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 127)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874155a",
   "metadata": {},
   "source": [
    "### Neural Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d400943",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_labels = yy.shape[1]\n",
    "\n",
    "filter_size = 2\n",
    "\n",
    "def build_model_graph(input_shape=(40,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_labels))\n",
    "    model.add(Activation('softmax'))\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') \n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model_graph()\n",
    "\n",
    "# Display model architecture summary \n",
    "model(x_train)\n",
    "model.summary()# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e750c",
   "metadata": {},
   "source": [
    "### Model Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee43c4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: {0:.2%}\".format(score[1]))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: {0:.2%}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d565231b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321af7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
